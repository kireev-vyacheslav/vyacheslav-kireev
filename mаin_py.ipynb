{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "840652d8-04ba-4ce7-878b-cbcd2dc7bacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (49496, 11)\n",
      "Test shape: (21184, 10)\n",
      "Создание фич...\n",
      "\n",
      "Подготовка данных для модели...\n",
      "Количество фич: 32\n",
      "Примеры фич: ['query_in_title', 'word_overlap', 'word_overlap_ratio', 'jaccard', 'contains_all', 'title_starts_with_query', 'query_len', 'title_len', 'query_word_count', 'title_word_count']\n",
      "\n",
      "============================================================\n",
      "ОБУЧЕНИЕ МОДЕЛИ\n",
      "============================================================\n",
      "\n",
      "Fold 1/5\n",
      "----------------------------------------\n",
      "Train samples: 39596\n",
      "Val samples: 9900\n",
      "Fold 1 nDCG@10: 0.8372\n",
      "\n",
      "Топ-10 важных фич:\n",
      "  char_3gram_overlap: 23713.62\n",
      "  bm25_score: 3662.18\n",
      "  composite_score_group_norm: 3609.98\n",
      "  word_overlap_ratio_group_norm: 3094.06\n",
      "  query_len: 2997.73\n",
      "  len_ratio: 2897.79\n",
      "  title_len: 2808.67\n",
      "  composite_score: 2374.66\n",
      "  bm25_score_group_norm: 2342.96\n",
      "  query_word_count: 2237.65\n",
      "\n",
      "Fold 2/5\n",
      "----------------------------------------\n",
      "Train samples: 39597\n",
      "Val samples: 9899\n",
      "Fold 2 nDCG@10: 0.8440\n",
      "\n",
      "Fold 3/5\n",
      "----------------------------------------\n",
      "Train samples: 39597\n",
      "Val samples: 9899\n",
      "Fold 3 nDCG@10: 0.8391\n",
      "\n",
      "Fold 4/5\n",
      "----------------------------------------\n",
      "Train samples: 39597\n",
      "Val samples: 9899\n",
      "Fold 4 nDCG@10: 0.8413\n",
      "\n",
      "Fold 5/5\n",
      "----------------------------------------\n",
      "Train samples: 39597\n",
      "Val samples: 9899\n",
      "Fold 5 nDCG@10: 0.8531\n",
      "\n",
      "============================================================\n",
      "РЕЗУЛЬТАТЫ ВАЛИДАЦИИ\n",
      "============================================================\n",
      "Средний nDCG@10 по фолдам: 0.8430 (±0.0056)\n",
      "OOF nDCG@10: 0.8430\n",
      "\n",
      "Анализ предсказаний по relevance:\n",
      "  Relevance 0:  8027 samples, pred: 1.845 ± 0.339\n",
      "  Relevance 1:  3189 samples, pred: 2.046 ± 0.269\n",
      "  Relevance 2: 17969 samples, pred: 2.010 ± 0.262\n",
      "  Relevance 3: 20311 samples, pred: 2.098 ± 0.267\n",
      "\n",
      "Применяем постобработку...\n",
      "Усилено 695 exact matches (+0.5)\n",
      "Усилено 2029 contains_all matches (+0.3)\n",
      "Усилено 179 title_starts_with_query (+0.2)\n",
      "Усилено 2580 brand_in_query (+0.15)\n",
      "\n",
      "Применяем group-wise enhancement...\n",
      "\n",
      "============================================================\n",
      "СОЗДАНИЕ SUBMISSION\n",
      "============================================================\n",
      "\n",
      "Статистика предсказаний:\n",
      "Min: 0.486835\n",
      "Max: 3.852733\n",
      "Mean: 2.090324\n",
      "Std: 0.397673\n",
      "Median: 2.102072\n",
      "\n",
      "Перцентили:\n",
      "    0%: 0.4868\n",
      "    1%: 1.1382\n",
      "    5%: 1.4359\n",
      "   25%: 1.9090\n",
      "   50%: 2.1021\n",
      "   75%: 2.2327\n",
      "   95%: 2.8403\n",
      "   99%: 3.3367\n",
      "  100%: 3.8527\n",
      "\n",
      "============================================================\n",
      "✓ SUBMISSION СОХРАНЕН: E:\\submission.csv\n",
      "Размер: (21184, 2)\n",
      "============================================================\n",
      "\n",
      "Первые 5 строк:\n",
      "   id  prediction\n",
      "0   0    1.150694\n",
      "1   1    1.327514\n",
      "2   2    0.794116\n",
      "3   3    1.122052\n",
      "4   4    1.339493\n",
      "\n",
      "Решение готово!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "import json\n",
    "from collections import Counter\n",
    "import gc\n",
    "\n",
    "SEED = 993\n",
    "np.random.seed(SEED)\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "\n",
    "# Предобработка текста\n",
    "def quick_preprocess(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    text_cols = ['query', 'product_title', 'product_description', 'product_bullet_point']\n",
    "    for col in text_cols:\n",
    "        df[col] = df[col].fillna('')\n",
    "    \n",
    "    cat_cols = ['product_brand', 'product_color']\n",
    "    for col in cat_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna('unknown')\n",
    "    \n",
    "    def clean_text(text):\n",
    "        text = str(text).lower()\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        text = ' '.join(text.split())\n",
    "        return text\n",
    "    \n",
    "    for col in text_cols:\n",
    "        df[col] = df[col].apply(clean_text)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = quick_preprocess(train)\n",
    "test = quick_preprocess(test)\n",
    "\n",
    "# Создание фич\n",
    "def create_optimal_features(df, vectorizer=None, is_train=True):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Текстовые совпадения\n",
    "    df['query_in_title'] = df.apply(\n",
    "        lambda x: int(x['query'] in x['product_title']), axis=1\n",
    "    )\n",
    "    \n",
    "    def word_overlap(row):\n",
    "        query_words = set(row['query'].split())\n",
    "        title_words = set(row['product_title'].split())\n",
    "        \n",
    "        if not query_words:\n",
    "            return 0, 0, 0, 0\n",
    "        \n",
    "        intersect = len(query_words & title_words)\n",
    "        union = len(query_words | title_words)\n",
    "        \n",
    "        return pd.Series({\n",
    "            'word_overlap': intersect,\n",
    "            'word_overlap_ratio': intersect / len(query_words),\n",
    "            'jaccard': intersect / union if union > 0 else 0,\n",
    "            'contains_all': int(query_words.issubset(title_words))\n",
    "        })\n",
    "    \n",
    "    overlap_features = df.apply(word_overlap, axis=1)\n",
    "    df = pd.concat([df, overlap_features], axis=1)\n",
    "    \n",
    "    df['title_starts_with_query'] = df.apply(\n",
    "        lambda x: int(x['product_title'].startswith(x['query'])), axis=1\n",
    "    )\n",
    "    \n",
    "    # Статистики\n",
    "    df['query_len'] = df['query'].str.len()\n",
    "    df['title_len'] = df['product_title'].str.len()\n",
    "    df['query_word_count'] = df['query'].str.split().str.len()\n",
    "    df['title_word_count'] = df['product_title'].str.split().str.len()\n",
    "    \n",
    "    df['len_ratio'] = df['title_len'] / (df['query_len'] + 1e-5)\n",
    "    df['word_count_ratio'] = df['title_word_count'] / (df['query_word_count'] + 1e-5)\n",
    "    \n",
    "    # Бренд и цвет\n",
    "    if 'product_brand' in df.columns:\n",
    "        df['brand_in_query'] = df.apply(\n",
    "            lambda x: int(any(brand_word in x['query'] \n",
    "                             for brand_word in str(x['product_brand']).lower().split()\n",
    "                             if len(brand_word) > 2)), axis=1\n",
    "        )\n",
    "        df['has_brand'] = (~df['product_brand'].isin(['unknown', ''])).astype(int)\n",
    "    \n",
    "    if 'product_color' in df.columns:\n",
    "        df['color_in_query'] = df.apply(\n",
    "            lambda x: int(any(color_word in x['query']\n",
    "                             for color_word in str(x['product_color']).lower().split()\n",
    "                             if len(color_word) > 2)), axis=1\n",
    "        )\n",
    "        df['has_color'] = (df['product_color'] != 'unknown').astype(int)\n",
    "    \n",
    "    # BM25\n",
    "    def bm25_similarity(row):\n",
    "        query = row['query']\n",
    "        title = row['product_title']\n",
    "        \n",
    "        if not query or not title:\n",
    "            return 0\n",
    "        \n",
    "        query_words = query.split()\n",
    "        title_words = title.split()\n",
    "        \n",
    "        if not query_words or not title_words:\n",
    "            return 0\n",
    "        \n",
    "        avg_doc_len = np.mean([len(w) for w in title_words])\n",
    "        \n",
    "        k1 = 1.5\n",
    "        b = 0.75\n",
    "        \n",
    "        score = 0\n",
    "        for word in query_words:\n",
    "            if word in title_words:\n",
    "                tf = title_words.count(word)\n",
    "                idf = np.log((len(title_words) + 1) / (title_words.count(word) + 0.5))\n",
    "                score += idf * (tf * (k1 + 1)) / (tf + k1 * (1 - b + b * len(title_words) / avg_doc_len))\n",
    "        \n",
    "        return score / len(query_words)\n",
    "    \n",
    "    df['bm25_score'] = df.apply(bm25_similarity, axis=1)\n",
    "    \n",
    "    # TF-IDF cosine similarity\n",
    "    if is_train:\n",
    "        corpus = pd.concat([df['query'], df['product_title']]).unique()\n",
    "        vectorizer = TfidfVectorizer(\n",
    "            max_features=100,\n",
    "            ngram_range=(1, 2),\n",
    "            stop_words='english',\n",
    "            min_df=2\n",
    "        )\n",
    "        vectorizer.fit(corpus)\n",
    "        global tfidf_vectorizer\n",
    "        tfidf_vectorizer = vectorizer\n",
    "    else:\n",
    "        vectorizer = tfidf_vectorizer\n",
    "    \n",
    "    query_tfidf = vectorizer.transform(df['query'])\n",
    "    title_tfidf = vectorizer.transform(df['product_title'])\n",
    "    \n",
    "    batch_size = 1000\n",
    "    cosine_sims = []\n",
    "    \n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch_end = min(i + batch_size, len(df))\n",
    "        batch_query = query_tfidf[i:batch_end]\n",
    "        batch_title = title_tfidf[i:batch_end]\n",
    "        batch_sim = cosine_similarity(batch_query, batch_title).diagonal()\n",
    "        cosine_sims.extend(batch_sim)\n",
    "    \n",
    "    df['tfidf_cosine'] = cosine_sims\n",
    "    \n",
    "    # Character n-gram overlap\n",
    "    def char_ngram_overlap(text1, text2, n=3):\n",
    "        if len(text1) < n or len(text2) < n:\n",
    "            return 0\n",
    "        \n",
    "        ngrams1 = set([text1[i:i+n] for i in range(len(text1)-n+1)])\n",
    "        ngrams2 = set([text2[i:i+n] for i in range(len(text2)-n+1)])\n",
    "        \n",
    "        if not ngrams1:\n",
    "            return 0\n",
    "        \n",
    "        return len(ngrams1 & ngrams2) / len(ngrams1)\n",
    "    \n",
    "    df['char_3gram_overlap'] = df.apply(\n",
    "        lambda x: char_ngram_overlap(x['query'], x['product_title'], 3), axis=1\n",
    "    )\n",
    "    \n",
    "    # Композитный скор\n",
    "    df['composite_score'] = (\n",
    "        0.3 * df['query_in_title'] +\n",
    "        0.25 * df['contains_all'] +\n",
    "        0.15 * df['title_starts_with_query'] +\n",
    "        0.1 * df['jaccard'] +\n",
    "        0.08 * df['tfidf_cosine'] +\n",
    "        0.07 * df['bm25_score'] +\n",
    "        0.05 * df.get('brand_in_query', 0)\n",
    "    )\n",
    "    \n",
    "    # Group normalization\n",
    "    if 'query_id' in df.columns:\n",
    "        for feat in ['composite_score', 'tfidf_cosine', 'bm25_score', 'word_overlap_ratio']:\n",
    "            if feat in df.columns:\n",
    "                df[f'{feat}_group_norm'] = df.groupby('query_id')[feat].transform(\n",
    "                    lambda x: (x - x.mean()) / (x.std() + 1e-8)\n",
    "                )\n",
    "                df[f'{feat}_group_minmax'] = df.groupby('query_id')[feat].transform(\n",
    "                    lambda x: (x - x.min()) / (x.max() - x.min() + 1e-8)\n",
    "                )\n",
    "    \n",
    "    # Числовые совпадения\n",
    "    def extract_numbers(text):\n",
    "        numbers = re.findall(r'\\d+', str(text))\n",
    "        return [int(n) for n in numbers]\n",
    "    \n",
    "    df['query_numbers'] = df['query'].apply(extract_numbers)\n",
    "    df['title_numbers'] = df['product_title'].apply(extract_numbers)\n",
    "    df['number_match'] = df.apply(\n",
    "        lambda x: len(set(x['query_numbers']) & set(x['title_numbers'])) / \n",
    "        max(len(set(x['query_numbers'])), 1), axis=1\n",
    "    )\n",
    "    \n",
    "    df = df.drop(['query_numbers', 'title_numbers'], axis=1, errors='ignore')\n",
    "    \n",
    "    # Дополнительные фичи\n",
    "    df['first_word_match'] = df.apply(\n",
    "        lambda x: int(x['query'].split()[0] == x['product_title'].split()[0]) \n",
    "        if x['query'].split() and x['product_title'].split() else 0, axis=1\n",
    "    )\n",
    "    \n",
    "    if 'product_description' in df.columns:\n",
    "        df['desc_len'] = df['product_description'].str.len()\n",
    "        df['desc_has_query'] = df.apply(\n",
    "            lambda x: int(x['query'] in x['product_description']), axis=1\n",
    "        )\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Создание фич...\")\n",
    "train_features = create_optimal_features(train, is_train=True)\n",
    "test_features = create_optimal_features(test, is_train=False)\n",
    "\n",
    "# Подготовка фичей\n",
    "print(\"\\nПодготовка данных для модели...\")\n",
    "\n",
    "non_feature_cols = [\n",
    "    'id', 'query_id', 'query', 'product_title', 'product_description',\n",
    "    'product_bullet_point', 'product_brand', 'product_color', 'product_locale'\n",
    "]\n",
    "\n",
    "if 'relevance' in train_features.columns:\n",
    "    non_feature_cols.append('relevance')\n",
    "\n",
    "feature_cols = [col for col in train_features.columns \n",
    "                if col not in non_feature_cols \n",
    "                and pd.api.types.is_numeric_dtype(train_features[col])]\n",
    "\n",
    "print(f\"Количество фич: {len(feature_cols)}\")\n",
    "print(f\"Примеры фич: {feature_cols[:10]}\")\n",
    "\n",
    "for col in feature_cols:\n",
    "    train_features[col] = train_features[col].fillna(0).astype(np.float32)\n",
    "    test_features[col] = test_features[col].fillna(0).astype(np.float32)\n",
    "\n",
    "# Обучение модели\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ОБУЧЕНИЕ МОДЕЛИ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X = train_features[feature_cols].values\n",
    "y = train_features['relevance'].values\n",
    "groups = train_features['query_id'].values\n",
    "\n",
    "X_test = test_features[feature_cols].values\n",
    "\n",
    "best_params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 63,\n",
    "    'max_depth': 8,\n",
    "    'min_child_samples': 20,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.3,\n",
    "    'min_split_gain': 0.01,\n",
    "    'verbosity': -1,\n",
    "    'n_jobs': -1,\n",
    "    'seed': SEED,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.9,\n",
    "    'bagging_freq': 1,\n",
    "}\n",
    "\n",
    "n_folds = 5\n",
    "group_kfold = GroupKFold(n_splits=n_folds)\n",
    "\n",
    "oof_predictions = np.zeros(len(X))\n",
    "test_predictions = np.zeros(len(X_test))\n",
    "fold_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(group_kfold.split(X, y, groups)):\n",
    "    print(f\"\\nFold {fold + 1}/{n_folds}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    print(f\"Train samples: {len(X_train)}\")\n",
    "    print(f\"Val samples: {len(X_val)}\")\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        best_params,\n",
    "        train_data,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[val_data],\n",
    "        valid_names=['val'],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(100, verbose=False),\n",
    "            lgb.log_evaluation(0)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    val_pred = model.predict(X_val)\n",
    "    oof_predictions[val_idx] = val_pred\n",
    "    test_predictions += model.predict(X_test) / n_folds\n",
    "    \n",
    "    fold_ndcg_scores = []\n",
    "    unique_queries = np.unique(groups[val_idx])\n",
    "    \n",
    "    for query_id in unique_queries:\n",
    "        mask = groups[val_idx] == query_id\n",
    "        if mask.sum() > 1:\n",
    "            y_true_sub = y_val[mask].reshape(1, -1)\n",
    "            y_pred_sub = val_pred[mask].reshape(1, -1)\n",
    "            try:\n",
    "                ndcg = ndcg_score(y_true_sub, y_pred_sub, k=min(10, len(y_true_sub[0])))\n",
    "                fold_ndcg_scores.append(ndcg)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    fold_ndcg = np.mean(fold_ndcg_scores) if fold_ndcg_scores else 0\n",
    "    fold_scores.append(fold_ndcg)\n",
    "    print(f\"Fold {fold + 1} nDCG@10: {fold_ndcg:.4f}\")\n",
    "    \n",
    "    if fold == 0:\n",
    "        importance = pd.DataFrame({\n",
    "            'feature': feature_cols,\n",
    "            'gain': model.feature_importance(importance_type='gain')\n",
    "        }).sort_values('gain', ascending=False)\n",
    "        \n",
    "        print(\"\\nТоп-10 важных фич:\")\n",
    "        for i, row in importance.head(10).iterrows():\n",
    "            print(f\"  {row['feature']}: {row['gain']:.2f}\")\n",
    "    \n",
    "    del model, train_data, val_data\n",
    "    gc.collect()\n",
    "\n",
    "# OOF оценка\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"РЕЗУЛЬТАТЫ ВАЛИДАЦИИ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "train_features['oof_pred'] = oof_predictions\n",
    "oof_ndcg_scores = []\n",
    "\n",
    "for query_id in train_features['query_id'].unique():\n",
    "    query_data = train_features[train_features['query_id'] == query_id]\n",
    "    if len(query_data) > 1:\n",
    "        y_true = query_data['relevance'].values.reshape(1, -1)\n",
    "        y_pred = query_data['oof_pred'].values.reshape(1, -1)\n",
    "        try:\n",
    "            ndcg = ndcg_score(y_true, y_pred, k=min(10, len(query_data)))\n",
    "            oof_ndcg_scores.append(ndcg)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "print(f\"Средний nDCG@10 по фолдам: {np.mean(fold_scores):.4f} (±{np.std(fold_scores):.4f})\")\n",
    "print(f\"OOF nDCG@10: {np.mean(oof_ndcg_scores):.4f}\")\n",
    "\n",
    "print(\"\\nАнализ предсказаний по relevance:\")\n",
    "for rel in sorted(train_features['relevance'].unique()):\n",
    "    mask = train_features['relevance'] == rel\n",
    "    if mask.sum() > 0:\n",
    "        avg_pred = train_features.loc[mask, 'oof_pred'].mean()\n",
    "        std_pred = train_features.loc[mask, 'oof_pred'].std()\n",
    "        print(f\"  Relevance {rel}: {mask.sum():5d} samples, pred: {avg_pred:.3f} ± {std_pred:.3f}\")\n",
    "\n",
    "# Постобработка\n",
    "print(\"\\nПрименяем постобработку...\")\n",
    "\n",
    "final_test_predictions = test_predictions.copy()\n",
    "\n",
    "if 'query_in_title' in test_features.columns:\n",
    "    exact_mask = test_features['query_in_title'] == 1\n",
    "    if exact_mask.any():\n",
    "        boost_amount = 0.5\n",
    "        final_test_predictions[exact_mask] += boost_amount\n",
    "        print(f\"Усилено {exact_mask.sum()} exact matches (+{boost_amount})\")\n",
    "\n",
    "if 'contains_all' in test_features.columns:\n",
    "    all_mask = test_features['contains_all'] == 1\n",
    "    if all_mask.any():\n",
    "        boost_amount = 0.3\n",
    "        final_test_predictions[all_mask] += boost_amount\n",
    "        print(f\"Усилено {all_mask.sum()} contains_all matches (+{boost_amount})\")\n",
    "\n",
    "if 'title_starts_with_query' in test_features.columns:\n",
    "    starts_mask = test_features['title_starts_with_query'] == 1\n",
    "    if starts_mask.any():\n",
    "        boost_amount = 0.2\n",
    "        final_test_predictions[starts_mask] += boost_amount\n",
    "        print(f\"Усилено {starts_mask.sum()} title_starts_with_query (+{boost_amount})\")\n",
    "\n",
    "if 'brand_in_query' in test_features.columns:\n",
    "    brand_mask = test_features['brand_in_query'] == 1\n",
    "    if brand_mask.any():\n",
    "        boost_amount = 0.15\n",
    "        final_test_predictions[brand_mask] += boost_amount\n",
    "        print(f\"Усилено {brand_mask.sum()} brand_in_query (+{boost_amount})\")\n",
    "\n",
    "if 'query_id' in test_features.columns:\n",
    "    print(\"\\nПрименяем group-wise enhancement...\")\n",
    "    test_features['model_score'] = final_test_predictions\n",
    "    \n",
    "    for query_id in test_features['query_id'].unique():\n",
    "        mask = test_features['query_id'] == query_id\n",
    "        if mask.sum() > 1:\n",
    "            scores = final_test_predictions[mask]\n",
    "            score_range = scores.max() - scores.min()\n",
    "            if score_range < 0.1:\n",
    "                mean_score = scores.mean()\n",
    "                final_test_predictions[mask] = mean_score + (scores - mean_score) * 2.0\n",
    "            \n",
    "            if len(set(scores)) < len(scores):\n",
    "                noise = np.random.uniform(-0.0001, 0.0001, size=mask.sum())\n",
    "                final_test_predictions[mask] += noise\n",
    "\n",
    "# Создание submission\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"СОЗДАНИЕ SUBMISSION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'prediction': final_test_predictions\n",
    "})\n",
    "\n",
    "print(f\"\\nСтатистика предсказаний:\")\n",
    "print(f\"Min: {final_test_predictions.min():.6f}\")\n",
    "print(f\"Max: {final_test_predictions.max():.6f}\")\n",
    "print(f\"Mean: {final_test_predictions.mean():.6f}\")\n",
    "print(f\"Std: {final_test_predictions.std():.6f}\")\n",
    "print(f\"Median: {np.median(final_test_predictions):.6f}\")\n",
    "\n",
    "print(f\"\\nПерцентили:\")\n",
    "percentiles = [0, 1, 5, 25, 50, 75, 95, 99, 100]\n",
    "for p in percentiles:\n",
    "    value = np.percentile(final_test_predictions, p)\n",
    "    print(f\"  {p:3d}%: {value:.4f}\")\n",
    "\n",
    "submission_path = 'E:\\\\submission.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"✓ SUBMISSION СОХРАНЕН: {submission_path}\")\n",
    "print(f\"Размер: {submission.shape}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(f\"\\nПервые 5 строк:\")\n",
    "print(submission.head())\n",
    "\n",
    "print(\"\\nРешение готово!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d2379c-e26d-4eb9-9f1f-00e84fc28a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
